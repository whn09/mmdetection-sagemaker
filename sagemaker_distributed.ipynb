{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training MMDetection Mask-RCNN Model on Sagemaker Distributed Cluster\n",
    "\n",
    "## Motivation\n",
    "[MMDetection](https://github.com/open-mmlab/mmdetection) is a popular open-source Deep Learning framework focused on Computer Vision models and use cases. MMDetection provides to higher level APIs for model training and inference. It demonstrates [state-of-the-art benchmarks](https://github.com/open-mmlab/mmdetection#benchmark-and-model-zoo) for variety of model architecture and extensive Model Zoo.\n",
    "\n",
    "In this notebook, we will build a custom training container with MMdetection library and then train Mask-RCNN model from scratch on [COCO2017 dataset](https://cocodataset.org/#home) using Sagemaker distributed [training feature](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html) in order to reduce training time.\n",
    "\n",
    "### Preconditions\n",
    "- To execute this notebook, you will need to have COCO 2017 training and validation datasets uploaded to S3 bucket available for Amazon Sagemaker service.\n",
    "\n",
    "\n",
    "## Building Training Container\n",
    "\n",
    "Amazon Sagemaker allows to BYO containers for training, data processing, and inference. In our case, we need to build custom training container which will be pushed to your AWS account [ECR service](https://aws.amazon.com/ecr/). \n",
    "\n",
    "For this, we need to login to public ECR with Sagemaker base images and private ECR reposity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3\n",
    "\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "# login to Sagemaker ECR with Deep Learning Containers\n",
    "!aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin 763104351884.dkr.ecr.{region}.amazonaws.com\n",
    "# login to your private ECR\n",
    "!aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account}.dkr.ecr.{region}.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let review training container:\n",
    "- use Sagemaker PyTorch 1.5.0 container as base image;\n",
    "- install latest version of Pytorch libraries and MMdetection dependencies;\n",
    "- build MMDetection from sources;\n",
    "- configure Sagemaker env variables, specifically, what script to use at training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize -l docker Dockerfile.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "Next, we build and push custom training container to private ECR\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  5.338MB\n",
      "Step 1/13 : FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.5.0-gpu-py36-cu101-ubuntu16.04\n",
      " ---> 47cd15520b75\n",
      "Step 2/13 : LABEL author=\"vadimd@amazon.com\"\n",
      " ---> Using cache\n",
      " ---> 78da0851d3c4\n",
      "Step 3/13 : WORKDIR /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 07bd9a0de06d\n",
      "Step 4/13 : RUN pip install --upgrade --force-reinstall  torch torchvision cython\n",
      " ---> Using cache\n",
      " ---> b13c99508ae7\n",
      "Step 5/13 : RUN pip install mmcv-full==latest+torch1.7.0+cu101 -f https://download.openmmlab.com/mmcv/dist/index.html\n",
      " ---> Running in 02ad64588c07\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/index.html\n",
      "Collecting mmcv-full==latest+torch1.7.0+cu101\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/latest/torch1.7.0/cu101/mmcv_full-latest%2Btorch1.7.0%2Bcu101-cp36-cp36m-manylinux1_x86_64.whl (24.1 MB)\n",
      "Collecting yapf\n",
      "  Downloading yapf-0.30.0-py2.py3-none-any.whl (190 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from mmcv-full==latest+torch1.7.0+cu101) (1.19.4)\n",
      "Collecting addict\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from mmcv-full==latest+torch1.7.0+cu101) (5.3.1)\n",
      "Collecting opencv-python>=3\n",
      "  Downloading opencv_python-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (49.5 MB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages (from mmcv-full==latest+torch1.7.0+cu101) (8.0.1)\n",
      "Installing collected packages: yapf, addict, opencv-python, mmcv-full\n",
      "Successfully installed addict-2.4.0 mmcv-full-1.2.1 opencv-python-4.4.0.46 yapf-0.30.0\n",
      "\u001b[91mWARNING: You are using pip version 20.1; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 02ad64588c07\n",
      " ---> 7e525985aced\n",
      "Step 6/13 : RUN git clone https://github.com/open-mmlab/mmdetection\n",
      " ---> Running in 33aaeb7257c6\n",
      "\u001b[91mCloning into 'mmdetection'...\n",
      "\u001b[0mRemoving intermediate container 33aaeb7257c6\n",
      " ---> cecc8368f81a\n",
      "Step 7/13 : RUN cd mmdetection/ &&     pip install -e .\n",
      " ---> Running in 4deca66caff3\n",
      "Obtaining file:///opt/ml/code/mmdetection\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from mmdet==2.7.0) (3.2.1)\n",
      "Collecting mmpycocotools\n",
      "  Downloading mmpycocotools-12.0.3.tar.gz (23 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from mmdet==2.7.0) (1.19.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from mmdet==2.7.0) (1.14.0)\n",
      "Collecting terminaltables\n",
      "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->mmdet==2.7.0) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->mmdet==2.7.0) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->mmdet==2.7.0) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->mmdet==2.7.0) (1.2.0)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.6/site-packages (from mmpycocotools->mmdet==2.7.0) (46.1.3.post20200330)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.6/site-packages (from mmpycocotools->mmdet==2.7.0) (0.29.21)\n",
      "Building wheels for collected packages: mmpycocotools, terminaltables\n",
      "  Building wheel for mmpycocotools (setup.py): started\n",
      "  Building wheel for mmpycocotools (setup.py): finished with status 'done'\n",
      "  Created wheel for mmpycocotools: filename=mmpycocotools-12.0.3-cp36-cp36m-linux_x86_64.whl size=281857 sha256=123fc83411bc6592b4f7ac895ab80576f9ba1ce92192f1b0b2dde5c5803c50c1\n",
      "  Stored in directory: /root/.cache/pip/wheels/79/e9/2f/545d78370691036bb34a3781984de6236882e367c97060b1ac\n",
      "  Building wheel for terminaltables (setup.py): started\n",
      "  Building wheel for terminaltables (setup.py): finished with status 'done'\n",
      "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=621076d70f479ece8d51d1e13bdfae8de2aa8f505f483b8a706c0c67ffae401a\n",
      "  Stored in directory: /root/.cache/pip/wheels/86/1b/58/c23af2fe683acd8edc15d5a1268f0242be1ff2cf827fe34737\n",
      "Successfully built mmpycocotools terminaltables\n",
      "Installing collected packages: mmpycocotools, terminaltables, mmdet\n",
      "  Running setup.py develop for mmdet\n",
      "Successfully installed mmdet mmpycocotools-12.0.3 terminaltables-3.1.0\n",
      "\u001b[91mWARNING: You are using pip version 20.1; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 4deca66caff3\n",
      " ---> eb3be526f8a1\n",
      "Step 8/13 : ENV MKL_THREADING_LAYER GNU\n",
      " ---> Running in af53d4d3f262\n",
      "Removing intermediate container af53d4d3f262\n",
      " ---> 42ef3579878c\n",
      "Step 9/13 : ENV MMDETECTION /opt/ml/code/mmdetection\n",
      " ---> Running in f39aee62674e\n",
      "Removing intermediate container f39aee62674e\n",
      " ---> 2c8b5a528354\n",
      "Step 10/13 : COPY container_training /opt/ml/code\n",
      " ---> e9723f88d188\n",
      "Step 11/13 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Running in 91e043c39867\n",
      "Removing intermediate container 91e043c39867\n",
      " ---> 14cc94ccce4e\n",
      "Step 12/13 : ENV SAGEMAKER_PROGRAM mmdetection_train.py\n",
      " ---> Running in bd45d65cb541\n",
      "Removing intermediate container bd45d65cb541\n",
      " ---> 1c2b4034c0ac\n",
      "Step 13/13 : WORKDIR /\n",
      " ---> Running in 10a6c13f275b\n",
      "Removing intermediate container 10a6c13f275b\n",
      " ---> d555ef6a1c13\n",
      "Successfully built d555ef6a1c13\n",
      "Successfully tagged mmdetection-training:latest\n",
      "The push refers to repository [579019700964.dkr.ecr.us-east-1.amazonaws.com/mmdetection-training]\n",
      "\n",
      "\u001b[1B4dadcdfd: Preparing \n",
      "\u001b[1B87a896e8: Preparing \n",
      "\u001b[1B1cc404a9: Preparing \n",
      "\u001b[1B20bac855: Preparing \n",
      "\u001b[1B1aef3cb1: Preparing \n",
      "\u001b[1B87d2d613: Preparing \n",
      "\u001b[1Bdc6eccf1: Preparing \n",
      "\u001b[1Be8cb8ead: Preparing \n",
      "\u001b[1B18b6f784: Preparing \n",
      "\u001b[1Bbe96fc82: Preparing \n",
      "\u001b[1B2b332e53: Preparing \n",
      "\u001b[1Bc6e1c93f: Preparing \n",
      "\u001b[1B8af0cced: Preparing \n",
      "\u001b[1Ba1e058e6: Preparing \n",
      "\u001b[1Ba7e2d141: Preparing \n",
      "\u001b[1B891256c7: Preparing \n",
      "\u001b[1B4275da12: Preparing \n",
      "\u001b[1B8601ef26: Preparing \n",
      "\u001b[1B03245374: Preparing \n",
      "\u001b[1Be3aaa392: Preparing \n",
      "\u001b[1B09ca2db2: Preparing \n",
      "\u001b[1B3589d5b4: Preparing \n",
      "\u001b[1B3141886c: Preparing \n",
      "\u001b[1Bab783b62: Preparing \n",
      "\u001b[1B20da503d: Preparing \n",
      "\u001b[1Bdadd4466: Preparing \n",
      "\u001b[17Bb332e53: Waiting g \n",
      "\u001b[17B6e1c93f: Waiting g \n",
      "\u001b[22B8cb8ead: Waiting g \n",
      "\u001b[18Baf0cced: Waiting g \n",
      "\u001b[18B1e058e6: Waiting g \n",
      "\u001b[24B8b6f784: Waiting g \n",
      "\u001b[24Be96fc82: Waiting g \n",
      "\u001b[31B0bac855: Pushed   275.5MB/275MBMB4A\u001b[2K\u001b[34A\u001b[2K\u001b[28A\u001b[2K\u001b[33A\u001b[2K\u001b[31A\u001b[2K\u001b[25A\u001b[2K\u001b[31A\u001b[2K\u001b[24A\u001b[2K\u001b[34A\u001b[2K\u001b[32A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[31A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2Klatest: digest: sha256:0a67db7b3d89c243ff69e474871624bfbcfa77def68ac95e696e40490b133a3f size: 7471\n"
     ]
    }
   ],
   "source": [
    "! ./build_and_push.sh mmdetection-training latest Dockerfile.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training script\n",
    "\n",
    "At training time, Sagemaker executes training script defined in `SAGEMAKER_PROGRAM` variable. In our case, this script does following\n",
    "- parses user parameters passed via Sagemaker Hyperparameter dictionary;\n",
    "- based on parameters constructs launch command;\n",
    "- uses `torch.distributed.launch` utility to launch distributed training;\n",
    "- uses MMDetection `tools/train.py` to configure trianing process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize container_training/mmdetection_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Sagemaker Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "prefix_input = 'mmdetection-input'\n",
    "prefix_output = 'mmdetection-ouput'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = \"mmdetection-training\" # your container name\n",
    "tag = \"latest\"\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(account, region, container, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm parameters\n",
    "\n",
    "hyperparameters = {\n",
    "    \"config-file\" : \"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\", # config path is relative to MMDetection root directory\n",
    "    \"dataset\" : \"coco\",\n",
    "    \"auto-scale\" : \"false\", # whether to scale LR and Warm Up time\n",
    "    \"validate\" : \"true\", # whether to run validation after training is done\n",
    "    \n",
    "    # 'options' allows to override individual config values\n",
    "    \"options\" : \"total_epochs=1; optimizer.lr=0.08; evaluation.gpu_collect=True\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sagemaker will parse metrics from STDOUT and store/visualize them as part of training job\n",
    "metrics = [\n",
    "    {\n",
    "        \"Name\": \"loss\",\n",
    "        \"Regex\": \".*loss:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_rpn_cls\",\n",
    "        \"Regex\": \".*loss_rpn_cls:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_rpn_bbox\",\n",
    "        \"Regex\": \".*loss_rpn_bbox:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_cls\",\n",
    "        \"Regex\": \".*loss_cls:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"acc\",\n",
    "        \"Regex\": \".*acc:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_bbox\",\n",
    "        \"Regex\": \".*loss_bbox:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_mask\",\n",
    "        \"Regex\": \".*loss_mask:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"lr\",\n",
    "        \"Regex\": \"lr: (-?\\d+.?\\d*(?:[Ee]-\\d+)?)\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "Execute cell below to start training on Sagemaker.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://fast-ai-coco/train2017.zip to ./train2017.zip        \n",
      "download: s3://fast-ai-coco/val2017.zip to ./val2017.zip            \n",
      "download: s3://fast-ai-coco/test2017.zip to ./test2017.zip         \n"
     ]
    }
   ],
   "source": [
    "# !aws s3 cp s3://fast-ai-coco/coco_tiny.tgz .\n",
    "!aws s3 cp s3://fast-ai-coco/train2017.zip .\n",
    "!aws s3 cp s3://fast-ai-coco/val2017.zip .\n",
    "!aws s3 cp s3://fast-ai-coco/test2017.zip .\n",
    "!aws s3 cp s3://fast-ai-coco/annotations_trainval2017.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !tar -xvf coco_tiny.tgz\n",
    "!unzip train2017.zip\n",
    "!unzip val2017.zip\n",
    "!unzip test2017.zip\n",
    "!unzip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !aws s3 cp --recursive coco_tiny s3://$bucket/coco_tiny\n",
    "!aws s3 cp --recursive train2017 s3://$bucket/coco/train2017\n",
    "!aws s3 cp --recursive val2017 s3://$bucket/coco/val2017\n",
    "!aws s3 cp --recursive test2017 s3://$bucket/coco/test2017\n",
    "!aws s3 cp --recursive annotations s3://$bucket/coco/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_volume_size has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-10 10:39:49 Starting - Starting the training job...\n",
      "2020-12-10 10:40:15 Starting - Launching requested ML instancesProfilerReport-1607596789: InProgress\n",
      ".........\n",
      "2020-12-10 10:41:41 Starting - Preparing the instances for training.........\n",
      "2020-12-10 10:43:17 Downloading - Downloading input data...."
     ]
    }
   ],
   "source": [
    "est = sagemaker.estimator.Estimator(image,\n",
    "                                          role=role,\n",
    "                                          train_instance_count=2,\n",
    "                                          train_instance_type='ml.p3.8xlarge',\n",
    "                                          train_volume_size=100,\n",
    "                                          output_path=\"s3://{}/{}\".format(bucket, prefix_output),\n",
    "                                          metric_definitions = metrics,\n",
    "                                          hyperparameters = hyperparameters, \n",
    "                                          sagemaker_session=session\n",
    ")\n",
    "\n",
    "# est.fit({\"training\" : \"s3://\"+bucket+\"/coco_tiny/\"})\n",
    "est.fit({\"training\" : \"s3://\"+bucket+\"/coco/\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
